{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Twitter_breastcancer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB9DK0AvjZJy"
      },
      "source": [
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JObkUd_hjZJ2"
      },
      "source": [
        "consumer_key = 'GQxAxtDxWUCwptlX69czVg8GY'\n",
        "consumer_secret = 'CrMsD42fqWRv9PKN6BbwRJZc1y7jIN6WRqDVBGu0ksHV57dLSZ'\n",
        "access_token = '1092833345904492544-vWtPgqW2ZvviFNylHlANoVxYxQuGlR'\n",
        "access_token_secret = 'I9UFA0G2wA6J6ItbdJXBBu6LhvnfwRBLT0FYnCecF4pqi'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCSKWZUtjZJ4"
      },
      "source": [
        "import tweepy\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzmIz_HhjZJ7"
      },
      "source": [
        "from tweepy import Stream\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy.streaming import StreamListener\n",
        "import json\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re #regular expression\n",
        "from textblob import TextBlob\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk4Q5Jl9jZJ-"
      },
      "source": [
        "covid_tweets = 'breast-cancer.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhBM6nTNjZKA"
      },
      "source": [
        "COLS = ['id', 'created_at', 'source', 'original_text','clean_text', 'sentiment','polarity','subjectivity', 'lang',\n",
        "'favorite_count', 'retweet_count', 'original_author',   'possibly_sensitive', 'hashtags',\n",
        "'user_mentions', 'place', 'place_coord_boundaries']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-GKBucjZKD"
      },
      "source": [
        "emoticons_happy = set([\n",
        "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
        "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
        "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
        "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
        "    '<3'\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlQS_e68jZKG"
      },
      "source": [
        "# Sad Emoticons\n",
        "emoticons_sad = set([\n",
        "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
        "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
        "    ':c', ':{', '>:\\\\', ';('\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-5EAU6kjZKI"
      },
      "source": [
        "#Emoji patterns\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "         u\"\\U00002702-\\U000027B0\"\n",
        "         u\"\\U000024C2-\\U0001F251\"\n",
        "         \"]+\", flags=re.UNICODE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Gq0SOujZKK"
      },
      "source": [
        "#combine sad and happy emoticons\n",
        "emoticons = emoticons_happy.union(emoticons_sad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCwKWi-EjZKN"
      },
      "source": [
        "#mrhod clean_tweets()\n",
        "import os\n",
        "def clean_tweets(tweet):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(tweet)\n",
        "\n",
        "    #after tweepy preprocessing the colon left remain after removing mentions\n",
        "    #or RT sign in the beginning of the tweet\n",
        "    tweet = re.sub(r':', '', tweet)\n",
        "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
        "    #replace consecutive non-ASCII characters with a space\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
        "\n",
        "\n",
        "    #remove emojis from tweet\n",
        "    tweet = emoji_pattern.sub(r'', tweet)\n",
        "\n",
        "    #filter using NLTK library append it to a string\n",
        "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
        "    filtered_tweet = []\n",
        "\n",
        "    #looping through conditions\n",
        "    for w in word_tokens:\n",
        "        #check tokens against stop words , emoticons and punctuations\n",
        "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
        "            filtered_tweet.append(w)\n",
        "    return ' '.join(filtered_tweet)\n",
        "    #print(word_tokens)\n",
        "    #print(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1QDEVFEjZKP"
      },
      "source": [
        "#method write_tweets()\n",
        "def write_tweets(keyword, file):\n",
        "    # If the file exists, then read the existing data from the CSV file.\n",
        "    if os.path.exists(file):\n",
        "        df = pd.read_csv(file, header=0)\n",
        "    else:\n",
        "        df = pd.DataFrame(columns=COLS)\n",
        "    #page attribute in tweepy.cursor and iteration\n",
        "    for page in tweepy.Cursor(api.search, q=keyword,\n",
        "                              count=1000, include_rts=False, since=start_date, wait_on_rate_limit = True).pages(10000000):\n",
        "        for status in page:\n",
        "            new_entry = []\n",
        "            status = status._json\n",
        "\n",
        "            ## check whether the tweet is in english or skip to the next tweet\n",
        "            if status['lang'] != 'en':\n",
        "                continue\n",
        "\n",
        "            #when run the code, below code replaces the retweet amount and\n",
        "            #no of favorires that are changed since last download.\n",
        "            if status['created_at'] in df['created_at'].values:\n",
        "                i = df.loc[df['created_at'] == status['created_at']].index[0]\n",
        "                if status['favorite_count'] != df.at[i, 'favorite_count'] or \\\n",
        "                   status['retweet_count'] != df.at[i, 'retweet_count']:\n",
        "                    df.at[i, 'favorite_count'] = status['favorite_count']\n",
        "                    df.at[i, 'retweet_count'] = status['retweet_count']\n",
        "                continue\n",
        "\n",
        "\n",
        "           #tweepy preprocessing called for basic preprocessing\n",
        "            clean_text = status['text']\n",
        "\n",
        "            #call clean_tweet method for extra preprocessing\n",
        "            filtered_tweet=clean_tweets(clean_text)\n",
        "\n",
        "            #pass textBlob method for sentiment calculations\n",
        "            blob = TextBlob(filtered_tweet)\n",
        "            Sentiment = blob.sentiment\n",
        "\n",
        "            #seperate polarity and subjectivity in to two variables\n",
        "            polarity = Sentiment.polarity\n",
        "            subjectivity = Sentiment.subjectivity\n",
        "\n",
        "            #new entry append\n",
        "            new_entry += [status['id'], status['created_at'],\n",
        "                          status['source'], status['text'],filtered_tweet, Sentiment,polarity,subjectivity, status['lang'],\n",
        "                          status['favorite_count'], status['retweet_count']]\n",
        "\n",
        "            #to append original author of the tweet\n",
        "            new_entry.append(status['user']['screen_name'])\n",
        "\n",
        "            try:\n",
        "                is_sensitive = status['possibly_sensitive']\n",
        "            except KeyError:\n",
        "                is_sensitive = None\n",
        "            new_entry.append(is_sensitive)\n",
        "\n",
        "            # hashtagas and mentiones are saved using comma separted\n",
        "            hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
        "            new_entry.append(hashtags)\n",
        "            mentions = \", \".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\n",
        "            new_entry.append(mentions)\n",
        "\n",
        "            #get location of the tweet if possible\n",
        "            try:\n",
        "                location = status['user']['location']\n",
        "            except TypeError:\n",
        "                location = ''\n",
        "            new_entry.append(location)\n",
        "\n",
        "            try:\n",
        "                coordinates = [coord for loc in status['place']['bounding_box']['coordinates'] for coord in loc]\n",
        "            except TypeError:\n",
        "                coordinates = None\n",
        "            new_entry.append(coordinates)\n",
        "\n",
        "            single_tweet_df = pd.DataFrame([new_entry], columns=COLS)\n",
        "            df = df.append(single_tweet_df, ignore_index=True)\n",
        "    csvFile = open(file, 'a' ,encoding='utf-8')\n",
        "    df.to_csv(csvFile, mode='a', columns=COLS, index=False, encoding=\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMtbTSw9jZKS"
      },
      "source": [
        "keywords = '#breastcancer OR #breastcancersurvivor OR #goingflat OR #breastcancerawareness OR #mastectomy OR #busylivingwithmets OR #bccww OR #BCSM OR #breastcancerawarenessmonth OR #breastcancerwarrior' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brhrbDTKjZKV"
      },
      "source": [
        "#set two date variables for date range\n",
        "import datetime\n",
        "start_date= '2020-11-01'\n",
        "#end_date= '2020-11-30'\n",
        "#end_date =  datetime.datetime(2020, 29, , 0, 0, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2ih4o8BjZKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4644bbd5-82f9-4d62-cc4b-def2884e5ea0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22q7EoWJjZKX"
      },
      "source": [
        "write_tweets(keywords, covid_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7NtoLG_-WAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b0da7dd1-92aa-4f3b-9393-52b500501746"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('breast-cancer.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_13c05b7f-5eea-482b-a762-7114a6ad0643\", \"breast-cancer.csv\", 4922529)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}